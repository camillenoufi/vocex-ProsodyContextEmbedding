{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Contour_analysis.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"2lHzFrcKCzY-","colab_type":"code","colab":{}},"source":["#from analysis_helpers import load_learned_embeddings, create_filepaths\n","import pandas as pd \n","import numpy as np\n","import librosa\n","import scipy\n","import statistics as stat\n","import pickle as pkl\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qqdHVz34CzZC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":252},"outputId":"aad97914-5081-4ad8-b582-0463df68c984","executionInfo":{"status":"error","timestamp":1588724526106,"user_tz":360,"elapsed":1216,"user":{"displayName":"Camille Noufi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsrK35PcWhpkzZP4PrI5l8tNKsh07VlYDFs17ROg=s64","userId":"04628122647747040750"}}},"source":["DATASET = 'Var'\n","SIZE = 128\n","SKIP_WINDOW = 1\n","QUANT_FACTOR = 1\n","embeddings_filepath, reverse_dictionary_filepath, dictionary_filepath, w2i_filepath, w2c_filepath = create_filepaths(DATASET,SIZE,SKIP_WINDOW,QUANT_FACTOR)\n","E, _, _, _, w2c = load_learned_embeddings(embeddings_filepath,reverse_dictionary_filepath,dictionary_filepath,w2i_filepath, w2c_filepath)\n","print(E.shape)"],"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-e33a0d4ad848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mSKIP_WINDOW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mQUANT_FACTOR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0membeddings_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_dictionary_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2i_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2c_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_filepaths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSKIP_WINDOW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQUANT_FACTOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_learned_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_filepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse_dictionary_filepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdictionary_filepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2i_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2c_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'create_filepaths' is not defined"]}]},{"cell_type":"code","metadata":{"id":"ZQU6HRmzCzZG","colab_type":"code","colab":{}},"source":["words,vocab = np.load('data/sizesQ1_frVar.npy');\n","print(words,vocab)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WgbRfLbQCzZI","colab_type":"code","colab":{}},"source":["# pitch features\n","\n","def PitchMean(contour):\n","    return stat.mean(contour)\n","\n","def PitchSD(contour):\n","    return stat.pstdev(contour)\n","\n","def DerivativeMean(contour):\n","    return stat.mean(np.diff(contour))\n","\n","def DerivativeSD(contour):\n","    return stat.pstdev(np.diff(contour))\n","\n","def Length(contour, frame_length=11.6e-3):\n","    return frame_length*len(contour)\n","\n","def VibratoRate(contour, rate_median=6):\n","    #librosa.core.fft_frequencies(sr=(1/11.6e-3), n_fft=8)\n","    return librosa.segment.recurrence_matrix(contour)\n","def Lag(recmat):\n","    #librosa.core.fft_frequencies(sr=(1/11.6e-3), n_fft=8)\n","    return librosa.segment.recurrence_to_lag(recmat)\n","\n","def autocorr(x):\n","    n = len(x)\n","    variance = x.var()\n","    x = x-x.mean()\n","    r = np.correlate(x, x, mode = 'full')[-n:]\n","    assert np.allclose(r, np.array([(x[:n-k]*x[-(n-k):]).sum() for k in range(n)]))\n","    result = r/(variance*(np.arange(n, 0, -1)))\n","    return result\n","\n","def TremeloFreq(x, time_step=0.0116, nfft = 128):\n","    y = scipy.signal.detrend(x)\n","    #plt.plot(y)\n","    ps = (np.abs(np.fft.fftn(y,nfft))**2)/len(y)\n","    print(ps[:int(len(ps)/2)])\n","    freqs = librosa.core.fft_frequencies(sr=1/time_step, n_fft=nfft)\n","    freqs = freqs[1:]\n","    print(freqs)\n","    ps = ps[:int(len(ps)/2)]\n","    pks = scipy.signal.find_peaks(ps)\n","    fmax = freqs[np.argmax(ps)]\n","    print(fmax)\n","    plt.plot(freqs, ps)\n","    \n","\n","def extractContourFeatures(x):\n","    mean = PitchMean(x)\n","    sd = PitchSD(x)\n","    dmean = DerivativeMean(x)\n","    dsd = DerivativeSD(x)\n","    length = Length(x)\n","    fdict = {'mean':mean, 'sd':sd, 'dmean':dmean, 'dsd':dsd, 'length':length}\n","    return fdict"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qbWW9ZXJCzZK","colab_type":"code","colab":{}},"source":["section = 'Back'\n","contour_feature_dict = [extractContourFeatures(w2c[i][-15:]) for i in range(E.shape[0])]\n","outfile = 'data/contourFeatureDict{0}_Q{1}_frVar.pkl'.format(section,QUANT_FACTOR)\n","f = open(outfile,\"wb\")\n","pkl.dump(contour_feature_dict, f)\n","f.close()\n","print(section,\" saved\")\n","\n","section = 'Front'\n","contour_feature_dict = [extractContourFeatures(w2c[i][:15]) for i in range(E.shape[0])]\n","outfile = 'data/contourFeatureDict{0}_Q{1}_frVar.pkl'.format(section,QUANT_FACTOR)\n","f = open(outfile,\"wb\")\n","pkl.dump(contour_feature_dict, f)\n","f.close()\n","print(section,\" saved\")\n","\n","section = ''\n","contour_feature_dict = [extractContourFeatures(w2c[i]) for i in range(E.shape[0])]\n","outfile = 'data/contourFeatureDict{0}_Q{1}_frVar.pkl'.format(section,QUANT_FACTOR)\n","f = open(outfile,\"wb\")\n","pkl.dump(contour_feature_dict, f)\n","f.close()\n","print(section,\" saved\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hzk5puE_CzZN","colab_type":"code","colab":{}},"source":["contour_feature_dict[1]['length']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rnB-XB6pCzZP","colab_type":"code","colab":{}},"source":["def plotContourFeatureDistribution(contour_feature_dict, rng):\n","    fig, axs = plt.subplots(2, 3, tight_layout=True, figsize=(15,5))\n","    axs = axs.flatten()\n","    # We can set the number of bins with the `bins` kwarg\n","    n_bins = 100\n","    #fig.suptitle(\"W2C Indices {0} - {1}\".format(i_min,i_max), fontsize=20)\n","    axs[0].hist([contour_feature_dict[i]['mean'] for i in rng], bins=n_bins);\n","    axs[0].set_title('Mean')\n","    axs[1].hist([contour_feature_dict[i]['sd'] for i in rng], bins=n_bins);\n","    axs[1].set_title('SD')\n","    axs[2].hist([contour_feature_dict[i]['length'] for i in rng], bins=3);\n","    axs[2].set_xlim([0,6]); axs[2].set_title('Length')\n","    axs[3].hist([contour_feature_dict[i]['dmean'] for i in rng], bins=n_bins);\n","    axs[3].set_title('Deriv. Mean')\n","    axs[4].hist([contour_feature_dict[i]['dsd'] for i in rng], bins=n_bins);\n","    axs[4].set_title('Deriv. SD')\n","\n","plotContourFeatureDistribution( contour_feature_dict, range(0, E.shape[0]) )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RajmX1pVCzZS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}